@register_keras_serializable()
class PINN(tf.keras.Model):
    def __init__(self, input_dim=100, **kwargs):
        """
        Initializes the PINN model with an architecture optimized to learn
        smooth functions (C^2).

        Args:
            input_dim (int): The dimensionality of the network input (default: 100).
        """
        super(PINN, self).__init__(**kwargs)

        self.initializer_bias = tf.keras.initializers.RandomNormal(mean=0., stddev=0.1, seed=SEED)
        self.initializer = tf.keras.initializers.GlorotNormal(seed=SEED)
        self.l2_regularizer = tf.keras.regularizers.l2(0.001)
        self.input_dim = input_dim


        self.hidden_layers = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=(self.input_dim ,)),
            tf.keras.layers.Dense(128, activation='tanh', kernel_initializer=self.initializer, bias_initializer=self.initializer_bias, kernel_regularizer=self.l2_regularizer),
            tf.keras.layers.Dense(128, activation='tanh', kernel_initializer=self.initializer, bias_initializer=self.initializer_bias, kernel_regularizer=self.l2_regularizer),
            tf.keras.layers.Dense(128, activation='tanh', kernel_initializer=self.initializer, bias_initializer=self.initializer_bias, kernel_regularizer=self.l2_regularizer),
            tf.keras.layers.Dense(128, activation='tanh', kernel_initializer=self.initializer, bias_initializer=self.initializer_bias, kernel_regularizer=self.l2_regularizer),
        ])
        self.output_layer = tf.keras.layers.Dense(1, activation='softplus')

    @tf.function
    def call(self, inputs):
        z = self.hidden_layers(inputs)
        return self.output_layer(z)




def main(epochs, save_dir):
    
    @tf.function
    def loss_function(mu, G_pred, grad_log_G_pred, HESS_G_pred, ret, ret_mkt, tau, adp_lambda1, adp_lambda2):
        """
        Custom loss function for the PINN.

        Args:
            mu (tf.Tensor): Market weights.
            G_pred (tf.Tensor): Value of G predicted by the network.
            grad_log_G_pred (tf.Tensor): Gradient of log of G predicted by the network.
            HESS_G_pred (tf.Tensor): Hessian of G predicted by the network.
            ret (tf.Tensor): Stock returns.
            ret_mkt (tf.Tensor): The market return.
            tau (tf.Tensor): Relative covariance matrix.

        Returns:
            _type_: Loss values
        """
        ###################################################################################
        # # Functionally Generated Portfolio - Generated by the Neural Network function # #
        ###################################################################################

        inner_prod = tf.reduce_sum(mu * grad_log_G_pred, axis=1)
        pi_t = ((grad_log_G_pred + 1) - tf.expand_dims(inner_prod, axis=1))*mu

        # Shift weights to consider trade date at the end of the day
        pi_t_shifted = tf.concat([pi_t[:1], pi_t[:-1]], axis=0)
        # Portfolio return
        port_ret = tf.reduce_sum(pi_t_shifted * ret, axis=1)

        #########################
        # # Drift Calculation # #
        #########################
        T = tf.shape(pi_t)[0]

        mu_i = tf.expand_dims(mu, axis=2)     # (T, n, 1)
        mu_j = tf.expand_dims(mu, axis=1)     # (T, 1, n)

        # internal product μ_i μ_j: shape (T, n, n)
        mu_outer = mu_i * mu_j

        # elementwise: H * μ_i * μ_j * τ
        elementwise = HESS_G_pred * mu_outer * tau  # shape (T, n, n)

        # sum over i and j (last two dimensions)
        summed = tf.reduce_sum(elementwise, axis=[1, 2])  # shape (T,)
        dg_t = -0.5 * summed / G_pred

        # #########################
        # # # Drift integration # #
        # #########################
        base = tf.range(T)


        weights = tf.ones_like(dg_t, dtype=dg_t.dtype)
        if T % 2 == 1:  
            weights = tf.where(
                (base % 2 == 1) & (base != 0) & (base != T-1),
                tf.constant(4.0, dtype=dg_t.dtype),
                weights
            )
            weights = tf.where(
                (base % 2 == 0) & (base != 0) & (base != T-1),
                tf.constant(2.0, dtype=dg_t.dtype),
                weights
            )
            weights *= (1.0 / 3.0)
        else:  # Trapezoidal rule
            weights = tf.where(
                (base == 0) | (base == T-1),
                tf.constant(0.5, dtype=dg_t.dtype),
                tf.constant(1.0, dtype=dg_t.dtype)
            )
        g_t = tf.reduce_sum(weights * dg_t)

        # #######################
        # # # Master Eq Error # #
        # #######################

        G0 = G_pred[0]
        GT = G_pred[-1]
        right_hand_side = tf.math.log(GT[0]) - tf.math.log(G0[0]) + g_t

        # Cumulative log return
        port_cumulative_return = tf.math.exp(tf.reduce_sum(port_ret))
        mkt_cumulative_return = tf.math.exp(tf.reduce_sum(ret_mkt))
        left_hand_side = tf.math.log(port_cumulative_return) - tf.math.log(mkt_cumulative_return)

        equation_error = tf.square(left_hand_side - right_hand_side)  # Smooth, differentiable
        positivity_penalty = tf.square(tf.nn.relu(-g_t)) # Penalize negative drift

        total_loss = adp_lambda1 * equation_error + adp_lambda2 * positivity_penalty

        return total_loss, equation_error, positivity_penalty, g_t, pi_t

    @tf.function
    def train_step(model, optimizer, x, ret, ret_mkt, tau):
        with tf.GradientTape(persistent=True) as tape2:
            tape2.watch(x)
            with tf.GradientTape(persistent=True) as tape1:
                tape1.watch(x)
                G_pred = model(x)
                log_G_pred = tf.math.log(G_pred + 1e-7)
                grad_log_G = tape1.gradient(log_G_pred, x)
                grad_G     = tape1.gradient(G_pred, x) 

            H_G = tape2.batch_jacobian(grad_G, x)  # Hessian of G(x)
            total_loss, equation_error, positivity_penalty, g_t, pi_t = loss_function(mu=x, G_pred= G_pred, grad_log_G_pred= grad_log_G, HESS_G_pred= H_G, ret= ret, ret_mkt= ret_mkt, tau= tau, adp_lambda1= self_adp_lambda1, adp_lambda2= self_adp_lambda2)
        
        gradient_nn_wt = tape2.gradient(total_loss, model.trainable_variables)
        (gradient_self_adp) = tape2.gradient(total_loss, [self_adp_lambda1, self_adp_lambda2])

        optimizer.apply_gradients(zip(gradient_nn_wt, model.trainable_variables))

        return total_loss, equation_error, positivity_penalty, g_t, pi_t, gradient_self_adp, grad_G


    ###########################################################
    ## Initialize the model and the optimizer and parameters ##
    ###########################################################

    model =  PINN(input_dim=100)

    steps_bounds = [round(epochs / 5) ]
    lr_values = [1e-2, 1e-3]
    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(steps_bounds, lr_values)
    optimizer = tf.keras.optimizers.Adam(lr_schedule, beta_1=0.9, beta_2=0.95)
    optimizer_self_adp1 = tf.keras.optimizers.Adam(1e2, beta_1=0.9, beta_2=0.99)
    optimizer_self_adp2 = tf.keras.optimizers.Adam(1e2, beta_1=0.9, beta_2=0.99)


    #######################################
    ## Objects to store training metrics ##
    #######################################

    grad_norms_per_epoch = {}
    port_weights_per_epoch = {}

    avg_epoch_loss_vect = []
    drift_per_batch_vect = []
    lambda_1_vect = []
    lambda_2_vect = []

    ###########################################
    ## Initialize self adaptative parameters ##
    ###########################################

    self_adp_lambda1 = tf.cast(tf.ones([1,1]), dtype=tf.float32)
    self_adp_lambda2 = tf.cast(tf.ones([1,1]), dtype=tf.float32)

    self_adp_lambda1 = tf.Variable(self_adp_lambda1)
    self_adp_lambda2 = tf.Variable(self_adp_lambda2)

    #########################################
    ## Exit Training variables ##
    #########################################
    G_snapshots = {}  # Estimated function snapshots
    reference_epoch = 10 # Mean absolute error epoch

    for epoch in range(1,epochs+1):

        ################
        ## Train Step ##
        ################

        total_loss, equation_error, positivity_penalty, g_t, pi_t, gradient_self_adp, grad_G = train_step(model, optimizer, mu_train, stock_returns_train, mkt_ret_train, tau_train)


        #####################################
        ## Update self-adaptive parameters ##
        #####################################

        optimizer_self_adp1.apply_gradients(zip([-gradient_self_adp[0]], [self_adp_lambda1]))
        optimizer_self_adp2.apply_gradients(zip([-gradient_self_adp[1]], [self_adp_lambda2]))

        self_adp_lambda1.assign(tf.math.softplus(self_adp_lambda1))
        self_adp_lambda2.assign(tf.math.softplus(self_adp_lambda2))


        grad_norms_per_epoch[str(epoch)] = tf.norm(grad_G, ord='euclidean', axis=1)
        port_weights_per_epoch[str(epoch)] =  pi_t.numpy().tolist()
        drift_per_batch_vect.append(g_t.numpy())
        avg_epoch_loss_vect.append(total_loss.numpy()[0,0])
        lambda_1_vect.append(self_adp_lambda1.numpy()[0,0])
        lambda_2_vect.append(self_adp_lambda2.numpy()[0,0])


            
        epsilon_threshold_improvement = 10e-7  
        patience = 20
        start_epoch = 10 # Epoch to start Early Stop tracking 

        if epoch >= start_epoch:    
            G_snapshots[epoch] = model(mu_train, training=False).numpy().flatten()
            

        if epoch == reference_epoch + patience:
            G_now = model(mu_train, training=False).numpy().flatten()
            G_before = G_snapshots[reference_epoch]
            

            mea_change = np.mean(np.abs(G_now - G_before) )
            print(f"[EarlyStoppingCheck] Epoch {epoch}: MAE Change = {mea_change:.4e}")
            
            if mea_change < epsilon_threshold_improvement:
                print(f"Early stopping triggered at epoch {epoch}. MAE Change < {epsilon_threshold_improvement}")
                break

            reference_epoch = epoch
        
        if epoch % 10 == 0 or epoch == 1:
            print(f"Testing error for Epoch {epoch}:  total_loss: {total_loss.numpy()[0,0]}, master eq error: {equation_error.numpy()}, drift_penalty: {positivity_penalty.numpy()}, lambda1: {self_adp_lambda1.numpy()[0,0]}, lambda2: {self_adp_lambda2.numpy()[0,0]}")
    
    #################################################
    ## Save the model weights and training metrics ##
    #################################################

    model.save(os.path.join(save_dir, 'port_gen_func_nn.keras'))
    
    # Save training metrics (dictionaries and vectors)
    with open(os.path.join(save_dir, 'training_metrics.pkl'), 'wb') as f:
        pickle.dump({
            'grad_norms_per_epoch': grad_norms_per_epoch,
            'port_weights_per_epoch': port_weights_per_epoch,
            'drift_per_batch_vect': drift_per_batch_vect,
            'avg_epoch_loss_vect': avg_epoch_loss_vect,
            'lambda_1_vect': lambda_1_vect,
            'lambda_2_vect': lambda_2_vect,
            'G_snapshots': G_snapshots
        }, f)

    print(f"All artifacts saved to {save_dir}")

    return model

if __name__ == "__main__":
    model1 = main(100, os.environ['SAVE_DIR'])
    
           