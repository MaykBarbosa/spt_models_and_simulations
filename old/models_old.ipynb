{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiando os dados gerados anteriormente \n",
    "# Pesos do Portfolio de mercado\n",
    "mu_t_df = mkt_portfolio_weights.copy()\n",
    "\n",
    "# Retorno das ações\n",
    "R_t_df =  stocks_returns.copy()\n",
    "\n",
    "#Retorno do portfólio de mercado\n",
    "#Iloc[1:] para iniciar as series em 2004-01-05 e eliminar os valores NaN decorrentes do calculo do retorno. \n",
    "\n",
    "Y = tf.convert_to_tensor(mkt_return.iloc[1:], dtype=tf.float32)              # Retorno do portfólio de mercado\n",
    "X = tf.convert_to_tensor(mu_t_df.shift(1).iloc[1:].values, dtype=tf.float32) # Pesos de mercado\n",
    "\n",
    "# Prepare stock returns data (should align with training samples)\n",
    "stock_returns = tf.convert_to_tensor(R_t_df.iloc[1:].values, dtype=tf.float32)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = np.arange(len(X))\n",
    "train_idx, test_idx = train_test_split(indices, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Split datasets\n",
    "X_train = tf.convert_to_tensor(X.numpy()[train_idx], dtype=tf.float32)\n",
    "X_test  = tf.convert_to_tensor(X.numpy()[test_idx], dtype=tf.float32)\n",
    "\n",
    "Y_train = tf.convert_to_tensor(Y.numpy()[train_idx] , dtype=tf.float32)\n",
    "Y_test  = tf.convert_to_tensor(Y.numpy()[test_idx], dtype=tf.float32)\n",
    "\n",
    "stock_returns_train = tf.gather(stock_returns, train_idx)\n",
    "stock_returns_test = tf.gather(stock_returns, test_idx)\n",
    "\n",
    "\n",
    "input_dim =  X.shape[1] #100\n",
    "\n",
    "\n",
    "\n",
    "class PortfolioModel(tf.keras.Model):\n",
    "    def __init__(self, network):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        #self.stock_returns = tf.convert_to_tensor(stock_returns, dtype=tf.float32)\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        X, y_true = data\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            \n",
    "            # Compute gradient of log(G) with respect to INPUTS (X)\n",
    "            with tf.GradientTape() as inner_tape:\n",
    "                inner_tape.watch(X)\n",
    "                G = self.network(X)\n",
    "                log_G = tf.math.log(G + 1e-7)\n",
    "                \n",
    "            grad_log_G_X = inner_tape.gradient(log_G, X)\n",
    "            \n",
    "            # Calcula os pesos do portfólio\n",
    "            sum_term = tf.reduce_sum(X * grad_log_G_X, axis=1, keepdims=True)\n",
    "            pi_weights = X * (grad_log_G_X + 1 - sum_term)\n",
    "            port_returns = tf.reduce_sum(tf.reduce_sum(pi_weights*y_true, axis=1))\n",
    "            \n",
    "            mkt_return = tf.reduce_sum(tf.reduce_sum(X*y_true, axis=1))\n",
    "                        \n",
    "            # Custom loss calculation\n",
    "            loss = -(port_returns - mkt_return)\n",
    "            \n",
    "        # Compute gradients and update weights\n",
    "        trainable_vars = self.network.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        \n",
    "        del tape      \n",
    "        return {'loss': loss}\n",
    "    \n",
    "\n",
    "\n",
    "    # Build and train model\n",
    "l2_lambda = 0.0001\n",
    "base_network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_dim,)),\n",
    "    tf.keras.layers.Dense(input_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.Dense(1,  activation='softmax',bias_initializer=tf.keras.initializers.Constant(0.5)) #Softplus para garantir que o output (G) seja >0.\n",
    "])\n",
    "\n",
    "model = PortfolioModel(base_network)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "model.fit(x=tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(32), epochs=50)\n",
    "\n",
    "\n",
    "\n",
    "base_network = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_dim,)),\n",
    "    tf.keras.layers.Dense(256, kernel_regularizer=tf.keras.regularizers.l2(l2_lambda)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    \n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='softmax', bias_initializer=tf.keras.initializers.Constant(0.25))\n",
    "])\n",
    "\n",
    "model = PortfolioModel(base_network)\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001))\n",
    "history = model.fit(\n",
    "    x=tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64),\n",
    "    epochs=50,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Compute gradients for portfolio weights (critical step)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(X_test)\n",
    "    G_test = model.network(X_test)  \n",
    "    log_G_test = tf.math.log(G_test)\n",
    "\n",
    "grad_log_G_X_test = tape.gradient(log_G_test, X_test).numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate portfolio weights (same formula as training)\n",
    "sum_term_test = tf.reduce_sum(X_test * grad_log_G_X_test, axis=1, keepdims=True)\n",
    "pi_weights_test = X_test * (grad_log_G_X_test + 1 - sum_term_test)\n",
    "\n",
    "# Calculate portfolio returns\n",
    "portfolio_returns_test = tf.reduce_sum(pi_weights_test * stock_returns_test, axis=1)\n",
    "\n",
    "# Compare with true market returns (Y_test)\n",
    "#portfolio_performance = tf.reduce_mean(portfolio_returns_test - tf.squeeze(Y_test))\n",
    "\n",
    "# mkt Return\n",
    "mkt_ret_test = tf.reduce_sum(X_test*Y_test,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.plot(mkt_return_t_df.iloc[-539:].index,((1+portfolio_returns_test.numpy()).cumprod()-1),label='Retorno do portfolio gerado pela NN') \n",
    "plt.plot(mkt_return_t_df.iloc[-539:].index, ((1+mkt_ret_test.numpy()).cumprod()-1),label='Retorno do portfólio de Mercado')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599e118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a20215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bdf85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
